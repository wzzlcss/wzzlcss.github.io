<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Nonconvex Penalty | GSoC 2019 Final Report</title>
  <meta name="description" content="4 Nonconvex Penalty | GSoC 2019 Final Report" />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Nonconvex Penalty | GSoC 2019 Final Report" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Nonconvex Penalty | GSoC 2019 Final Report" />
  
  
  

<meta name="author" content="Qincheng Lu" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="optimize-mini-batching.html"/>
<link rel="next" href="poisson-models.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Overview</a></li>
<li class="chapter" data-level="2" data-path="new-saga-features.html"><a href="new-saga-features.html"><i class="fa fa-check"></i><b>2</b> New SAGA Features</a><ul>
<li class="chapter" data-level="2.1" data-path="new-saga-features.html"><a href="new-saga-features.html#c-saga"><i class="fa fa-check"></i><b>2.1</b> C-SAGA</a></li>
<li class="chapter" data-level="2.2" data-path="new-saga-features.html"><a href="new-saga-features.html#mini-batch-saga"><i class="fa fa-check"></i><b>2.2</b> Mini-batch SAGA</a></li>
<li class="chapter" data-level="2.3" data-path="new-saga-features.html"><a href="new-saga-features.html#simulated-data"><i class="fa fa-check"></i><b>2.3</b> Simulated Data</a></li>
<li class="chapter" data-level="2.4" data-path="new-saga-features.html"><a href="new-saga-features.html#observation-weight"><i class="fa fa-check"></i><b>2.4</b> Observation weight</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="optimize-mini-batching.html"><a href="optimize-mini-batching.html"><i class="fa fa-check"></i><b>3</b> Optimize mini-batching</a><ul>
<li class="chapter" data-level="3.1" data-path="optimize-mini-batching.html"><a href="optimize-mini-batching.html#optimal-batch-size-and-step-size-for-ridge"><i class="fa fa-check"></i><b>3.1</b> Optimal batch size and step size for ridge</a></li>
<li class="chapter" data-level="3.2" data-path="optimize-mini-batching.html"><a href="optimize-mini-batching.html#benchmark"><i class="fa fa-check"></i><b>3.2</b> Benchmark</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="nonconvex-penalty.html"><a href="nonconvex-penalty.html"><i class="fa fa-check"></i><b>4</b> Nonconvex Penalty</a><ul>
<li class="chapter" data-level="4.1" data-path="nonconvex-penalty.html"><a href="nonconvex-penalty.html#introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="nonconvex-penalty.html"><a href="nonconvex-penalty.html#mcp"><i class="fa fa-check"></i><b>4.2</b> MCP</a></li>
<li class="chapter" data-level="4.3" data-path="nonconvex-penalty.html"><a href="nonconvex-penalty.html#scad"><i class="fa fa-check"></i><b>4.3</b> SCAD</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="poisson-models.html"><a href="poisson-models.html"><i class="fa fa-check"></i><b>5</b> Poisson Models</a><ul>
<li class="chapter" data-level="5.1" data-path="poisson-models.html"><a href="poisson-models.html#overview-1"><i class="fa fa-check"></i><b>5.1</b> Overview</a></li>
<li class="chapter" data-level="5.2" data-path="poisson-models.html"><a href="poisson-models.html#example"><i class="fa fa-check"></i><b>5.2</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="reference.html"><a href="reference.html"><i class="fa fa-check"></i><b>6</b> Reference</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">GSoC 2019 Final Report</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="nonconvex-penalty" class="section level1">
<h1><span class="header-section-number">4</span> Nonconvex Penalty</h1>
<div id="introduction" class="section level2">
<h2><span class="header-section-number">4.1</span> Introduction</h2>
<p style="text-align:justify;">
In addition to lasso, ridge and elastic net penalty, <strong>sgdnet</strong> also fits along regularization path for linear regression using nonconvex penalties, which are minimax concave penalty (MCP) <span class="citation">(Zhang <a href="#ref-zhang2010">2010</a>)</span> and smoothly clipped absolute penalty (SCAD) <span class="citation">(Fan and Li <a href="#ref-fan2001">2001</a>)</span>.
</p>
<p style="text-align:justify;">
The ridge part in <strong>sgdnet</strong> use scale update <span class="math inline">\(\beta^{k + n} = \beta^{k} \prod _{i = 1}^{n}(1- \eta(1-\alpha) \lambda)\)</span>, where <span class="math inline">\(\lambda\)</span> is the regularization strength, <span class="math inline">\(\alpha\)</span> is elastic net mixing parameter and <span class="math inline">\(\eta\)</span> is the step size. Other penalties are applied via a proximal step at each iteration from the coefficient <span class="math inline">\(\beta^{k+\frac{1}{2}}\)</span> after the average gradient step. The proximal step solves a minimization problem:
</p>
<center>
<span class="math inline">\(\begin{aligned} \beta^{k + \frac{1}{2}} \leftarrow &amp; \, \beta^{k} - \eta \nabla \\ \beta^{k} \leftarrow &amp; \, \underset{\beta}{argmin} \Big( h_{\lambda}(\beta) + \frac{1}{2 \eta} \left \| \beta - \beta^{k + \frac{1}{2}} \right \|_2^2 \Big) \end{aligned}\)</span>
</center>
<p>where <span class="math inline">\(h_{\lambda}(\beta)\)</span> is the penalty function.</p>
</div>
<div id="mcp" class="section level2">
<h2><span class="header-section-number">4.2</span> MCP</h2>
<p style="text-align:justify;">
The definition for minimax concave penalty for each element of coefficient <span class="math inline">\(\beta\)</span> is given by:
</p>
<p><span class="math display">\[\begin{equation} p_{\lambda, \gamma}(\beta_j) = \begin{cases}
\lambda \beta_j - \frac{\beta_j^2}{2 \gamma} &amp; \text{if} \,\, |\beta_j| \leq \gamma \lambda \\ \frac{1}{2} \gamma \lambda^2 &amp; \text{otherwise}
\end{cases}\end{equation}\]</span></p>
<p style="text-align:justify;">
where <span class="math inline">\(\lambda \geq 0\)</span> is the regularization strength and <span class="math inline">\(\gamma &gt; 1\)</span> is a user defined nonconvexity parameter. We have <span class="math inline">\(h_{\lambda}(\beta) = p_{\alpha \lambda, \gamma}(\beta) + \frac{(1 - \alpha)\lambda}{2} ||\beta||_2^2\)</span> if user wants to mix ridge with MCP in the proximal step by setting <span class="math inline">\(\alpha\)</span> <span class="citation">(B. Huang Jian. and Zhang <a href="#ref-huang2016">2016</a>)</span>. The proximal operator for them is given by:
</p>
<p><span class="math display">\[\begin{equation} \beta_j \leftarrow \begin{cases} \frac{ \Big (1 - \eta \alpha \lambda \Big )_{+} \beta_j}{1 + \eta (1-\alpha)\lambda-\frac{\eta}{\gamma}} &amp; \text{if} \,\, |\beta_j| \leq \gamma \alpha \lambda \Big (1 + (1- \alpha) \lambda\Big ) \\ \frac{\beta_j}{1+\eta(1-\alpha)\lambda} &amp; \text{otherwise}. \end{cases} \end{equation}\]</span></p>
<p style="text-align:justify;">
MCP begins by applying the same rate of penalization as lasso, but continuously relaxes that penalization until <span class="math inline">\(\beta_j\)</span> becomes large <span class="citation">(Breheny and Huang <a href="#ref-breheny2011">2011</a>)</span>. When <span class="math inline">\(\alpha = 0\)</span>, this becomes the proximal updates for ridge <span class="citation">(Friedman, Hastie, and Tibshirani <a href="#ref-friedman2010">2010</a>)</span>. For MCP, <strong>sgdnet</strong> set the default noncovexity parameter <span class="math inline">\(\gamma\)</span> to <span class="math inline">\(3\)</span>. Here we use the example from <a href="https://cran.r-project.org/web/packages/ncvreg/index.html"><strong>ncvreg</strong></a> to demostrate its usage.
</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(prostate)
x &lt;-<span class="st"> </span>prostate<span class="op">$</span>x
y &lt;-<span class="st"> </span>prostate<span class="op">$</span>y
sgd_mcp  &lt;-<span class="st"> </span><span class="kw">sgdnet</span>(x, y, <span class="dt">non_convexity =</span> <span class="dv">3</span>, <span class="dt">penalty =</span> <span class="st">&quot;MCP&quot;</span>)
ncv_mcp  &lt;-<span class="st"> </span><span class="kw">ncvreg</span>(x, y, <span class="dt">gamma =</span> <span class="dv">3</span>, <span class="dt">penalty =</span> <span class="st">&quot;MCP&quot;</span>)
sgd_mnet &lt;-<span class="st"> </span><span class="kw">sgdnet</span>(x, y, <span class="dt">non_convexity =</span> <span class="dv">3</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>, <span class="dt">penalty =</span> <span class="st">&quot;MCP&quot;</span>)
ncv_mnet &lt;-<span class="st"> </span><span class="kw">ncvreg</span>(x, y, <span class="dt">gamma =</span> <span class="dv">3</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>, <span class="dt">penalty =</span> <span class="st">&quot;MCP&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/plotmcp-1.png" width="50%" style="display: inline-block;" /><img src="_main_files/figure-html/plotmcp-2.png" width="50%" style="display: inline-block;" /><img src="_main_files/figure-html/plotmcp-3.png" width="50%" style="display: inline-block;" /><img src="_main_files/figure-html/plotmcp-4.png" width="50%" style="display: inline-block;" /></p>
</div>
<div id="scad" class="section level2">
<h2><span class="header-section-number">4.3</span> SCAD</h2>
<p style="text-align:justify;">
Following the same notation, the definition for smoothly clipped absolute penalty for each element of coefficient <span class="math inline">\(\beta\)</span> is given by:
</p>
<p><span class="math display">\[\begin{equation} p_{\lambda, \gamma}(\beta_j) = \begin{cases} \lambda \beta_j &amp; \text{if} \, \,|\beta_j| \leq \lambda\\ \frac{\gamma \lambda \beta_j - \frac{1}{2} (\beta_j^2 + \lambda^2)}{\gamma - 1} \gamma \lambda^2 &amp; \text{if} \,\, \lambda &lt; |\beta_j| \leq \gamma \lambda \\ \frac{\lambda^2 (\gamma^2 - 1)}{2(\gamma - 1)} &amp; \text{therwise} \end{cases}  \end{equation}\]</span></p>
<p style="text-align:justify;">
where <span class="math inline">\(\lambda \geq 0\)</span> and <span class="math inline">\(\gamma &gt; 2\)</span>. The proximal operator for SCAD <span class="citation">(Wang <a href="#ref-zhu2016">2016</a>)</span> of strength <span class="math inline">\(\alpha \lambda\)</span>, with ridge of strength <span class="math inline">\((1-\alpha)\lambda\)</span> can be solved as:
</p>
<p><span class="math display">\[\begin{equation} \beta_j \leftarrow \begin{cases} 
\frac{\Big ( 1-\eta \alpha \lambda \Big )_{+} \beta_j}{1+\eta(1-\alpha)\lambda} &amp; \text{if} \, \,|\beta_j| \leq \alpha \lambda + \eta \alpha \lambda ( 1 + (1-\alpha) \lambda)\\ 
\frac{\Big ( 1 - \frac{\gamma}{ \gamma - 1} \eta \alpha \lambda \Big)_{+} \beta_j}{1- \frac{\eta}{\gamma - 1} + \eta (1- \alpha) \lambda} &amp; \text{if} \,\, \alpha \lambda + \eta \alpha \lambda ( 1 + (1-\alpha) \lambda) &lt; |\beta_j| \leq \gamma \alpha \lambda ( 1 + \eta (1 - \alpha) \lambda) \\ 
\frac{\beta_j}{1+\eta(1-\alpha)\lambda} &amp; \text{therwise} \end{cases}  \end{equation}\]</span></p>
<p style="text-align:justify;">
Similar to MCP, SCAD begins by applying lasso’s penalization rate, and reduces the rate to 0 as <span class="math inline">\(\beta_j\)</span> gets away from 0. The difference is in the way to make this transition. <strong>sgdnet</strong> has a default nonconvexity parameter <span class="math inline">\(\gamma = 3.7\)</span>. It can be specified by the <code>non_convexity</code> variable in <code>sgdnet()</code> function.
</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sgd_scad &lt;-<span class="st"> </span><span class="kw">sgdnet</span>(x, y, <span class="dt">non_convexity =</span> <span class="fl">3.7</span>, <span class="dt">penalty =</span> <span class="st">&quot;SCAD&quot;</span>)
ncv_scad &lt;-<span class="st"> </span><span class="kw">ncvreg</span>(x, y, <span class="dt">gamma =</span> <span class="fl">3.7</span>, <span class="dt">penalty =</span> <span class="st">&quot;SCAD&quot;</span>)
sgd_snet &lt;-<span class="st"> </span><span class="kw">sgdnet</span>(x, y, <span class="dt">non_convexity =</span> <span class="fl">3.7</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>, <span class="dt">penalty =</span> <span class="st">&quot;SCAD&quot;</span>)
ncv_snet &lt;-<span class="st"> </span><span class="kw">ncvreg</span>(x, y, <span class="dt">gamma =</span> <span class="fl">3.7</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>, <span class="dt">penalty =</span> <span class="st">&quot;SCAD&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/plotscad-1.png" width="50%" style="display: inline-block;" /><img src="_main_files/figure-html/plotscad-2.png" width="50%" style="display: inline-block;" /><img src="_main_files/figure-html/plotscad-3.png" width="50%" style="display: inline-block;" /><img src="_main_files/figure-html/plotscad-4.png" width="50%" style="display: inline-block;" /></p>

</div>
</div>
<h3> Reference</h3>
<div id="refs" class="references">
<div id="ref-breheny2011">
<p>Breheny, Patrick, and Jian Huang. 2011. “Coordinate Descent Algorithms for Nonconvex Penalized Regression, with Application to Biological Feature Selection.” <em>The Annals of Applied Statistics</em> 5 (1): 232–53.</p>
</div>
<div id="ref-fan2001">
<p>Fan, Jianqing, and Runze Li. 2001. “Variable Selection via Nonconcave Penalized Likelihood and Its Oracle Properties.” <em>Journal of the American Statistical Association</em> 38 (2): 1348–60.</p>
</div>
<div id="ref-friedman2010">
<p>Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. 2010. “Regularization Paths for Generalized Linear Models via Coordinate Descent.” <em>Journal of Statistical Software</em> 33 (1): 1–22.</p>
</div>
<div id="ref-huang2016">
<p>Huang, Breheny, Jian., and Cun-Hui Zhang. 2016. “The Mnet Method for Variable Selection.” <em>Statistica Sinica</em> 26 (3): 903–23.</p>
</div>
<div id="ref-zhu2016">
<p>Wang, Zhu et al. 2016. “Penalized Count Data Regression with Application to Hospital Stay After Pediatric Cardiac Surgery.” <em>Stat Methods Med Res</em> 25 (6): 2685–2703.</p>
</div>
<div id="ref-zhang2010">
<p>Zhang, Cun-Hui. 2010. “Nearly Unbiased Variable Selection Under Minimax Concave Penalty.” <em>The Annals of Applied Statistics</em> 38 (2): 894–942.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="optimize-mini-batching.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="poisson-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
